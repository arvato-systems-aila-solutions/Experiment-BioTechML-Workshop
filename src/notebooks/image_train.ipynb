{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0574ef-b559-410d-a849-1f1e1440d432",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Classification with BreastMNIST\n",
    "## A Practical Guide to Medical Image ML (90 minutes)\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Workshop Overview\n",
    "\n",
    "Welcome! In this tutorial, you'll learn how to build **machine learning models for medical image classification**. We'll work with the BreastMNIST dataset and compare traditional ML methods with deep learning approaches.\n",
    "\n",
    "### üéØ What You'll Learn\n",
    "\n",
    "1. **Data Exploration** (20 min) - Understanding medical image data\n",
    "2. **Model Training** (50 min) - Building and comparing multiple models\n",
    "3. **Model Evaluation** (20 min) - Analyzing performance metrics\n",
    "\n",
    "---\n",
    "\n",
    "### üìä About Our Dataset\n",
    "\n",
    "We're working with **BreastMNIST** - ultrasound images of breast tissue:\n",
    "- 28x28 grayscale images\n",
    "- Binary classification: Benign (0) vs Malignant (1)\n",
    "- Real medical imaging data\n",
    "\n",
    "**Goal**: Classify breast ultrasound images to aid in cancer diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Prerequisites Check\n",
    "\n",
    "First, let's verify all required libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check required libraries and their versions\n",
    "required_libs = {\n",
    "    \"medmnist\": \"3.0\",\n",
    "    \"numpy\": \"1.24\",\n",
    "    \"scikit-learn\": \"1.3\",\n",
    "    \"matplotlib\": \"3.7\",\n",
    "    \"seaborn\": \"0.12\",\n",
    "    \"tensorflow\": \"2.13\",\n",
    "    \"scipy\": \"1.10\"\n",
    "}\n",
    "\n",
    "print(\"üîç Checking installed libraries...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for lib_name, min_version in required_libs.items():\n",
    "    try:\n",
    "        if lib_name == \"scikit-learn\":\n",
    "            import sklearn\n",
    "            lib = sklearn\n",
    "            actual_name = \"sklearn\"\n",
    "        else:\n",
    "            lib = __import__(lib_name)\n",
    "            actual_name = lib_name\n",
    "        \n",
    "        installed_version = lib.__version__\n",
    "        print(f\"‚úì {lib_name}: {installed_version} (required: >={min_version})\")\n",
    "    except ImportError:\n",
    "        print(f\"‚úó {lib_name} is NOT installed. Please install it using:\")\n",
    "        print(f\"   pip install {lib_name}>={min_version}\")\n",
    "\n",
    "print(\"\\n‚úÖ Library check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e179b11-81a4-46e9-80d8-97501960ab6d",
   "metadata": {},
   "source": [
    "## üîç STEP 1: Data Exploration\n",
    "\n",
    "Let's understand our medical image dataset before diving into modeling!\n",
    "\n",
    "### üì• Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851630a3-7590-45e0-81f0-42123f57cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import BreastMNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üì• Loading BreastMNIST dataset...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load dataset\n",
    "train_ds = BreastMNIST(split='train', download=True)\n",
    "val_ds = BreastMNIST(split='val', download=True)\n",
    "test_ds = BreastMNIST(split='test', download=True)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = train_ds.imgs.reshape(len(train_ds), -1)\n",
    "y_train = train_ds.labels.flatten()\n",
    "\n",
    "X_val = val_ds.imgs.reshape(len(val_ds), -1)\n",
    "y_val = val_ds.labels.flatten()\n",
    "\n",
    "X_test = test_ds.imgs.reshape(len(test_ds), -1)\n",
    "y_test = test_ds.labels.flatten()\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Validation samples: {len(X_val)}\")\n",
    "print(f\"   Test samples: {len(X_test)}\")\n",
    "print(f\"   Image dimensions: 28x28 pixels\")\n",
    "print(f\"   Flattened features: {X_train.shape[1]} pixels\")\n",
    "print(f\"   Classes: 2 (0=Benign, 1=Malignant)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd54824-916e-4548-8b8e-e149425ceea6",
   "metadata": {},
   "source": [
    "### üîÑ Data Preparation for Traditional ML\n",
    "\n",
    "For traditional ML models (Logistic Regression, Random Forest, etc.), we need to:\n",
    "1. Flatten images from 28x28 to 784 features\n",
    "2. Normalize pixel values using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f5294-531f-4cd6-8e5e-44290db1d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî¢ Data Shape After Normalization:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Training set:   {X_train.shape[0]:>5} samples √ó {X_train.shape[1]:>3} features\")\n",
    "print(f\"   Validation set: {X_val.shape[0]:>5} samples √ó {X_val.shape[1]:>3} features\")\n",
    "print(f\"   Test set:       {X_test.shape[0]:>5} samples √ó {X_test.shape[1]:>3} features\")\n",
    "print(f\"\\n‚úÖ Data normalized and ready for traditional ML models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb4738-4f18-4b66-b68f-9d8ebe233338",
   "metadata": {},
   "source": [
    "### üìä Class Distribution Analysis\n",
    "\n",
    "Let's check if our dataset is balanced between benign and malignant cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a81766-fba3-482f-aa3b-8e92df1871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Analyzing class distribution...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(y_train, bins=2, edgecolor=\"black\", color=['#2ecc71', '#e74c3c'])\n",
    "plt.xticks([0,1], ['Benign', 'Malignant'])\n",
    "plt.title(\"Class Distribution in Training Set\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "benign_count = (y_train==0).sum()\n",
    "malignant_count = (y_train==1).sum()\n",
    "total = len(y_train)\n",
    "\n",
    "print(f\"\\nüìà Class Distribution:\")\n",
    "print(f\"   Benign (0):    {benign_count:>4} samples ({benign_count/total*100:.1f}%)\")\n",
    "print(f\"   Malignant (1): {malignant_count:>4} samples ({malignant_count/total*100:.1f}%)\")\n",
    "print(f\"   Total:         {total:>4} samples\")\n",
    "\n",
    "if abs(benign_count - malignant_count) / total > 0.2:\n",
    "    print(\"\\n‚ö†Ô∏è  Dataset is imbalanced! Consider using stratified sampling or class weights.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Dataset is reasonably balanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c6242-1847-462d-bb7d-1602908c0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "print(\"\\nüñºÔ∏è  Sample Images from Training Set:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Note: X_train is normalized, we need to use original images\n",
    "X_train_original = train_ds.imgs\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(12):\n",
    "    idx = random.randint(0, len(X_train_original)-1)\n",
    "    plt.subplot(2, 6, i+1)\n",
    "    plt.imshow(X_train_original[idx], cmap=\"gray\")\n",
    "    label_text = \"Benign\" if y_train[idx] == 0 else \"Malignant\"\n",
    "    plt.title(f\"{label_text}\", fontsize=9)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Random Sample Images\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c47bc2-d4c4-4e8f-ab6d-20d106cc7d8c",
   "metadata": {},
   "source": [
    "### üî¢ Pixel Intensity Statistics\n",
    "\n",
    "Understanding pixel value distributions helps us verify normalization and detect potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718f6c8-1610-4ec6-b243-7c9ec57de87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìâ Pixel Intensity Statistics (After Normalization):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Minimum:       {X_train.min():>8.4f}\")\n",
    "print(f\"   Maximum:       {X_train.max():>8.4f}\")\n",
    "print(f\"   Mean:          {X_train.mean():>8.4f}\")\n",
    "print(f\"   Std Deviation: {X_train.std():>8.4f}\")\n",
    "print(\"\\nüí° After StandardScaler, mean should be ~0 and std ~1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e6b32-f423-463e-97af-0b88ef9a54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(X_train.ravel(), bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Pixel Intensity Distribution (Normalized)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Normalized Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fa579-2611-4eb3-9d39-876eb5f2c1bc",
   "metadata": {},
   "source": [
    "### üî¨ Compare Class-wise Intensity Differences\n",
    "\n",
    "Sometimes malignant vs benign images differ subtly in their pixel intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a65ee1-c049-4270-9abb-273f7829de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = X_train[y_train == 0]\n",
    "malignant = X_train[y_train == 1]\n",
    "\n",
    "print(\"\\nüîç Mean Pixel Intensity by Class:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   Benign mean:    {benign.mean():>8.4f}\")\n",
    "print(f\"   Malignant mean: {malignant.mean():>8.4f}\")\n",
    "print(f\"   Difference:     {abs(benign.mean() - malignant.mean()):>8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24261ca-3dd4-422e-bbae-3c164abc1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.hist(benign.ravel(), bins=50, alpha=0.6, label=\"Benign\", density=True, color='#2ecc71')\n",
    "plt.hist(malignant.ravel(), bins=50, alpha=0.6, label=\"Malignant\", density=True, color='#e74c3c')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Normalized Pixel Intensity Distribution by Class\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Normalized Pixel Value\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab4977-8fab-4a99-8dfe-4a46f32a88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(benign.ravel(), label=\"Benign\", color='#2ecc71', linewidth=2)\n",
    "sns.kdeplot(malignant.ravel(), label=\"Malignant\", color='#e74c3c', linewidth=2)\n",
    "plt.title(\"KDE Pixel Intensity Distribution\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Normalized Pixel Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b502b-61a0-4399-a569-9ef7e7ba682f",
   "metadata": {},
   "source": [
    "### üé® Check Image Similarity using PCA (2D Visualization)\n",
    "\n",
    "Flatten images ‚Üí reduce to 2 principal components ‚Üí scatter plot to visualize class separability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046442b2-9b8b-45f9-93bd-a397989cdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"\\nüé® Performing PCA for 2D visualization...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "X_flat = X_train.reshape(len(X_train), -1)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_flat)\n",
    "\n",
    "print(f\"   Explained variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "print(f\"   PC1: {pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"   PC2: {pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap=\"coolwarm\", s=3, alpha=0.6)\n",
    "plt.title(\"PCA of BreastMNIST (2D Projection)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.colorbar(scatter, label=\"Label (0=Benign, 1=Malignant)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ PCA visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532351e6-b371-4184-bf36-a354fa56c7a5",
   "metadata": {},
   "source": [
    "### üì∏ Average Images per Class\n",
    "\n",
    "This visualization is extremely insightful for medical data - it shows the \"typical\" appearance of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b416421-7bc5-401d-a2ad-c2152333cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì∏ Computing average images per class...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "avg_benign = benign.mean(axis=0)\n",
    "avg_malignant = malignant.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(avg_benign.reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"Average Benign Image\", fontsize=12, fontweight='bold')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(avg_malignant.reshape((28, 28)), cmap=\"gray\")\n",
    "plt.title(\"Average Malignant Image\", fontsize=12, fontweight='bold')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Average images computed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99b040-96ec-4d02-8c5b-818a9835aab1",
   "metadata": {},
   "source": [
    "### üîç Difference Map\n",
    "\n",
    "Visualizing the difference between average malignant and benign images reveals key discriminative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147dcef-ca84-43ea-b5bd-395d7f345a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "diff_map = abs(avg_malignant.reshape((28, 28)) - avg_benign.reshape((28, 28)))\n",
    "plt.imshow(diff_map, cmap=\"seismic\")\n",
    "plt.title(\"Difference Map (|Malignant - Benign|)\", fontsize=14, fontweight='bold')\n",
    "plt.colorbar(label=\"Absolute Difference\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Max difference: {diff_map.max():.4f}\")\n",
    "print(f\"   Mean difference: {diff_map.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cd271-8b07-458c-a84b-886bee6ee126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "\n",
    "print(\"\\nüìä Computing confidence intervals...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Means\n",
    "mean_b = benign.mean(axis=0)\n",
    "mean_m = malignant.mean(axis=0)\n",
    "\n",
    "# Standard error\n",
    "sem_b = sem(benign, axis=0)\n",
    "sem_m = sem(malignant, axis=0)\n",
    "\n",
    "# 95% CI\n",
    "ci_low_b = mean_b - 1.96 * sem_b\n",
    "ci_high_b = mean_b + 1.96 * sem_b\n",
    "\n",
    "ci_low_m = mean_m - 1.96 * sem_m\n",
    "ci_high_m = mean_m + 1.96 * sem_m\n",
    "\n",
    "print(\"‚úÖ Confidence intervals computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d7d2a-1d73-4b7e-8cce-a8e0cb8b03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_width_b = (ci_high_b - ci_low_b).reshape(28, 28)\n",
    "ci_width_m = (ci_high_m - ci_low_m).reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(ci_width_b, cmap=\"magma\")\n",
    "plt.title(\"CI Width (Benign)\", fontsize=12, fontweight='bold')\n",
    "plt.colorbar(label=\"CI Width\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(ci_width_m, cmap=\"magma\")\n",
    "plt.title(\"CI Width (Malignant)\", fontsize=12, fontweight='bold')\n",
    "plt.colorbar(label=\"CI Width\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà CI Analysis:\")\n",
    "print(f\"   Benign - Mean CI width:    {ci_width_b.mean():.4f}\")\n",
    "print(f\"   Malignant - Mean CI width: {ci_width_m.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7242061-13e4-482a-94dd-6b53e6f46cc6",
   "metadata": {},
   "source": [
    "## ü§ñ STEP 2: Model Training (50 minutes)\n",
    "\n",
    "Now let's train multiple machine learning models and compare their performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af089c3c-728c-4b51-b2d0-e1f495a7156c",
   "metadata": {},
   "source": [
    "### üìà Model 1: Logistic Regression\n",
    "\n",
    "A simple linear classifier - our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02d9cc-66a7-4ed6-9016-7e9ff120a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "print(\"\\nüîÑ Training Logistic Regression...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "logreg_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Logistic Regression trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {logreg_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {logreg_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {logreg_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {logreg_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd839fd-de3b-4b6f-84df-3d8adb828a6a",
   "metadata": {},
   "source": [
    "### üå≤ Model 2: Random Forest\n",
    "\n",
    "An ensemble of decision trees for more complex pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c375e-f3a1-417e-a984-c7d9a1f1ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "print(\"\\nüå≤ Training Random Forest...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "rf_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Random Forest trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {rf_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {rf_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {rf_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {rf_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac6d94-d1d6-4698-8eb6-3b8fe43a58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nüå≥ Visualizing first decision tree from Random Forest...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Take the first decision tree from the Random Forest\n",
    "estimator = rf.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(estimator, \n",
    "          filled=True,\n",
    "          feature_names=[f\"pixel_{i}\" for i in range(X_train.shape[1])],\n",
    "          class_names=[\"Benign\", \"Malignant\"],\n",
    "          max_depth=5,     \n",
    "          fontsize=6)\n",
    "plt.title(\"First Decision Tree (max_depth=5 for visualization)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Note: This is just one of 200 trees in the Random Forest!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc4099-283e-4263-aa0d-691f4e270426",
   "metadata": {},
   "source": [
    "### üöÄ Model 3: XGBoost (Optional)\n",
    "\n",
    "Gradient boosting for high performance - commented out for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a4bc2-0a3b-4bf8-8188-c0d6b1520957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# params = {\n",
    "#     \"max_depth\": [3, 4, 5],\n",
    "#     \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "#     \"n_estimators\": [200, 400],\n",
    "#     \"subsample\": [0.7, 0.9],\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(\n",
    "#     xgb.XGBClassifier(eval_metric=\"logloss\"),\n",
    "#     param_grid=params,\n",
    "#     cv=3,\n",
    "#     scoring=\"accuracy\",\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Beste Parameter:\", grid.best_params_)\n",
    "# print(\"Beste Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d7deb-b74b-4007-a8cd-df9f12a22856",
   "metadata": {},
   "source": [
    "### üéØ Model 4: Support Vector Machine (SVM)\n",
    "\n",
    "A powerful classifier using the RBF kernel for non-linear decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98fd5d-c05c-4dea-82a9-9ea11436db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\nüéØ Training SVM with RBF kernel...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", C=5, gamma=\"scale\", random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "svm_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ SVM trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {svm_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {svm_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {svm_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {svm_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad57a5b-f52e-4fda-960b-ef614d8b752d",
   "metadata": {},
   "source": [
    "### üë• Model 5: K-Nearest Neighbors (KNN)\n",
    "\n",
    "Instance-based learning - classifies based on similarity to training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533bd81-9ab2-44e4-8124-33aab6ba2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"\\nüîç Finding optimal K for KNN...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "k_values = range(1, 51)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "print(f\"\\n‚úÖ Best K: {best_k} with accuracy: {max(accuracies):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(k_values, accuracies, marker=\"o\", linewidth=2)\n",
    "plt.axvline(x=best_k, color='r', linestyle='--', label=f'Best K={best_k}')\n",
    "plt.xlabel(\"Number of Neighbors (K)\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.title(\"KNN Elbow Criterion - Finding Optimal K\", fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0e153-039e-4091-afa1-d97a495a5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(f\"\\nüë• Training KNN with k={best_k}...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "knn_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ KNN trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {knn_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {knn_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {knn_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {knn_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a530f4-dc2a-48f0-8354-9c3297ab39d8",
   "metadata": {},
   "source": [
    "### üìä Model 6: Naive Bayes\n",
    "\n",
    "A probabilistic classifier based on Bayes' theorem with Gaussian distribution assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f7157-72bf-47be-86c9-0ebb29f261d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\nüìä Training Naive Bayes (Gaussian)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "nb_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ Naive Bayes trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {nb_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {nb_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {nb_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {nb_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f063f-33a7-463a-983d-fc471ac3abd7",
   "metadata": {},
   "source": [
    "### üî¨ Model 7: PCA + SVM\n",
    "\n",
    "Dimensionality reduction with PCA before SVM classification to reduce computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a6b38-aaae-431b-a5ba-8e655a6b96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "print(\"\\nüî¨ Training PCA + SVM...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"   Reduced from {X_train.shape[1]} to {X_train_pca.shape[1]} features\")\n",
    "print(f\"   Explained variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "svm_pca = SVC(kernel=\"rbf\", C=5, gamma=\"scale\", random_state=42)\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_pca.predict(X_test_pca)\n",
    "\n",
    "# Metrics\n",
    "svm_pca_results = {\n",
    "    \"accuracy\":  accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\":    recall_score(y_test, y_pred),\n",
    "    \"f1_score\":  f1_score(y_test, y_pred),\n",
    "    \"train_time_sec\": train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ PCA + SVM trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {svm_pca_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {svm_pca_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {svm_pca_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {svm_pca_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81df6c5-6f5a-4f04-9b06-5241844cd7d9",
   "metadata": {},
   "source": [
    "### üß† Model 8: Convolutional Neural Network (CNN)\n",
    "\n",
    "Deep learning approach - CNNs are specifically designed for image data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317d1e1-e921-406d-8b8f-f53c554287cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from medmnist import BreastMNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\nüñºÔ∏è  Preparing data for CNN...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load datasets\n",
    "train_ds = BreastMNIST(split='train', download=True)\n",
    "test_ds  = BreastMNIST(split='test',  download=True)\n",
    "\n",
    "# Images as float32 + normalization to [0,1]\n",
    "X_full = train_ds.imgs.astype(\"float32\") / 255.0\n",
    "y_full = train_ds.labels.flatten().astype(\"int32\")\n",
    "\n",
    "X_test_cnn = test_ds.imgs.astype(\"float32\") / 255.0\n",
    "y_test_cnn = test_ds.labels.flatten().astype(\"int32\")\n",
    "\n",
    "# Add channel dimension ‚Üí (N, 28, 28, 1)\n",
    "X_full     = X_full[..., np.newaxis]\n",
    "X_test_cnn = X_test_cnn[..., np.newaxis]\n",
    "\n",
    "print(f\"   Full train shape: {X_full.shape}\")\n",
    "print(f\"   Test shape: {X_test_cnn.shape}\")\n",
    "\n",
    "# Create train/validation split\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(\n",
    "    X_full, y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data prepared for CNN\")\n",
    "print(f\"   Training:   {X_train_cnn.shape[0]} samples\")\n",
    "print(f\"   Validation: {X_val_cnn.shape[0]} samples\")\n",
    "print(f\"   Test:       {X_test_cnn.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e66331-2a12-4ca5-9d40-692c4b2db722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Building CNN architecture...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')   # 1 output neuron for binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ CNN architecture built!\")\n",
    "print(\"\\nüìê Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_cnn_breastmnist.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Using Early Stopping (patience=5) and Model Checkpointing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b13c6-924b-48ed-8d9d-aee58ed6fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\nüöÄ Training CNN...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training + Time measurement\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train_cnn,\n",
    "    validation_data=(X_val_cnn, y_val_cnn),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Evaluation\n",
    "y_prob = model.predict(X_test_cnn, verbose=0)\n",
    "y_pred = (y_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "cnn_results = {\n",
    "    \"accuracy\":        accuracy_score(y_test_cnn, y_pred),\n",
    "    \"precision\":       precision_score(y_test_cnn, y_pred),\n",
    "    \"recall\":          recall_score(y_test_cnn, y_pred),\n",
    "    \"f1_score\":        f1_score(y_test_cnn, y_pred),\n",
    "    \"train_time_sec\":  train_time\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úÖ CNN trained in {train_time:.2f} seconds\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"   Accuracy:  {cnn_results['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {cnn_results['precision']:.4f}\")\n",
    "print(f\"   Recall:    {cnn_results['recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {cnn_results['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a32bd-d101-438e-9aef-f27a6ac8ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nüìà Visualizing training history...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc', linewidth=2)\n",
    "plt.title(\"Accuracy over Epochs\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.title(\"Loss over Epochs\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['auc'], label='Train AUC', linewidth=2)\n",
    "plt.plot(history.history['val_auc'], label='Val AUC', linewidth=2)\n",
    "plt.title(\"AUC over Epochs\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Training visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc62ce-b300-4b9d-8486-6eb22aa377b2",
   "metadata": {},
   "source": [
    "## üìä STEP 3: Model Comparison & Results (20 minutes)\n",
    "\n",
    "Let's compare all models side by side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437c2f5-9159-4953-b4de-69e37933ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\nüìä Compiling all model results...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    \"Logistic Regression\": logreg_results,\n",
    "    \"Random Forest\": rf_results,\n",
    "    \"SVM\": svm_results,\n",
    "    \"Naive Bayes\": nb_results,\n",
    "    \"KNN\": knn_results,\n",
    "    \"SVM + PCA\": svm_pca_results,\n",
    "    \"CNN\": cnn_results\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(all_results).T   # .T = Transpose, so models are rows\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "# Sort by F1-Score\n",
    "results_df = results_df.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"\\n‚úÖ Results compiled!\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìà MODEL COMPARISON TABLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "display(results_df)\n",
    "\n",
    "# Find best model\n",
    "best_model = results_df.index[0]\n",
    "best_f1 = results_df.loc[best_model, 'f1_score']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"üèÜ BEST MODEL: {best_model}\")\n",
    "print(f\"   F1-Score: {best_f1:.4f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af52f6d-0b1d-431a-9a24-c6d7b669628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\nüìä Visualizing model comparison...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "axes[0, 0].barh(results_df.index, results_df['accuracy'], color='#3498db')\n",
    "axes[0, 0].set_xlabel('Accuracy', fontsize=11)\n",
    "axes[0, 0].set_title('Model Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: F1-Score comparison\n",
    "axes[0, 1].barh(results_df.index, results_df['f1_score'], color='#2ecc71')\n",
    "axes[0, 1].set_xlabel('F1-Score', fontsize=11)\n",
    "axes[0, 1].set_title('Model F1-Score Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 3: Training time comparison\n",
    "axes[1, 0].barh(results_df.index, results_df['train_time_sec'], color='#e74c3c')\n",
    "axes[1, 0].set_xlabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1, 0].set_title('Model Training Time Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 4: Precision vs Recall\n",
    "axes[1, 1].scatter(results_df['recall'], results_df['precision'], s=200, alpha=0.7, color='#9b59b6')\n",
    "for idx, model in enumerate(results_df.index):\n",
    "    axes[1, 1].annotate(model, \n",
    "                        (results_df.loc[model, 'recall'], results_df.loc[model, 'precision']),\n",
    "                        fontsize=8, ha='right')\n",
    "axes[1, 1].set_xlabel('Recall', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Precision', fontsize=11)\n",
    "axes[1, 1].set_title('Precision vs Recall', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd1dc0-38ea-42df-9a98-265488021be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üéì Summary & Key Takeaways\n",
    "\n",
    "### üìù What We Learned\n",
    "\n",
    "1. **Data Exploration**: Medical images can be analyzed using statistical methods (PCA, class averages, confidence intervals)\n",
    "2. **Traditional ML**: Models like Random Forest and SVM work well even on flattened images\n",
    "3. **Deep Learning**: CNNs are specifically designed for images and often achieve superior performance\n",
    "4. **Trade-offs**: Consider accuracy vs training time vs model complexity\n",
    "\n",
    "### üîë Key Insights\n",
    "\n",
    "- **Best Performance**: Check the results table above to see which model performed best\n",
    "- **Training Speed**: Traditional ML models (LogReg, NB) train much faster than CNNs\n",
    "- **Feature Engineering**: PCA can reduce dimensions while maintaining performance\n",
    "- **Medical Context**: High recall is often more important than precision in cancer detection\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "- Try hyperparameter tuning (GridSearchCV)\n",
    "- Experiment with data augmentation for CNN\n",
    "- Test on different medical imaging datasets\n",
    "- Implement ensemble methods combining multiple models\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You've completed the medical image classification workshop!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
