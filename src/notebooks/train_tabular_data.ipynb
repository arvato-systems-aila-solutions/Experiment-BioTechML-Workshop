{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c786229b",
   "metadata": {},
   "source": [
    "# üß¨ Machine Learning Workshop: From Raw Data to Best Model\n",
    "## A Beginner's Guide to ML Workflow (100 minutes)\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Workshop Overview\n",
    "\n",
    "Welcome! In this tutorial, you'll learn the **complete machine learning workflow** from scratch. We'll work with a biotech dataset and go through every step a data scientist takes when building a model.\n",
    "\n",
    "### üéØ What You'll Learn\n",
    "\n",
    "1. **Data Exploration** (15 min) - Understanding your dataset\n",
    "2. **Data Cleaning** (20 min) - Handling messy real-world data\n",
    "3. **Feature Engineering** (15 min) - Creating useful features\n",
    "4. **Data Preparation** (10 min) - Getting ready for ML\n",
    "5. **Model Training** (25 min) - Building multiple models\n",
    "6. **Model Evaluation** (10 min) - Comparing performance\n",
    "7. **Model Selection** (5 min) - Choosing the best model\n",
    "\n",
    "---\n",
    "\n",
    "### üìä About Our Dataset\n",
    "\n",
    "We're working with biotech medical data containing:\n",
    "- Patient demographics (age, sex, height, weight)\n",
    "- Lab measurements (protein, glucose, albumin, pH)\n",
    "- Clinical information (diagnosis, treatment, sample quality)\n",
    "\n",
    "**Goal**: Predict patient diagnosis (Healthy vs Tumor) based on available features.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Prerequisites Check\n",
    "\n",
    "First, let's verify all required libraries are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898821a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check required libraries and their versions\n",
    "required_libs = {\n",
    "    \"pandas\": \"2.2\",\n",
    "    \"numpy\": \"2.0\",\n",
    "    \"scikit-learn\": \"1.7.2\",\n",
    "    \"matplotlib\": \"3.9\",\n",
    "    \"seaborn\": \"0.13.2\"\n",
    "}\n",
    "\n",
    "print(\"Checking installed libraries...\\n\")\n",
    "\n",
    "for lib_name, min_version in required_libs.items():\n",
    "    try:\n",
    "        if lib_name == \"scikit-learn\":\n",
    "            import sklearn\n",
    "            lib = sklearn\n",
    "            actual_name = \"sklearn\"\n",
    "        else:\n",
    "            lib = __import__(lib_name)\n",
    "            actual_name = lib_name\n",
    "        \n",
    "        installed_version = lib.__version__\n",
    "        print(f\"‚úì {lib_name}: {installed_version} (required: >={min_version})\")\n",
    "    except ImportError:\n",
    "        print(f\"‚úó {lib_name} is NOT installed. Please install it using:\")\n",
    "        print(f\"   pip install {lib_name}>={min_version}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35117b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "base_dir = Path().resolve().parent.parent\n",
    "os.chdir(base_dir)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f1dcb",
   "metadata": {},
   "source": [
    "## üîç STEP 1: Data Exploration (15 minutes)\n",
    "\n",
    "Let's understand our dataset before diving into modeling!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = os.path.join(\"data\", \"refinement\", \"biotech_preprocessing_refined.csv\")\n",
    "try:\n",
    "    df = pd.read_csv(data_path, index_col=0)\n",
    "    print(f\"‚úÖ Loaded dataset: {data_path} with shape {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚úó Could not find {data_path}. Check the data folder or use the raw CSV instead.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's peek at the first few rows\n",
    "print(\"\\nüëÄ First Look at the Data:\")\n",
    "print(\"=\" * 70)\n",
    "display(df.head(10))\n",
    "\n",
    "print(f\"\\nüìè Dataset Dimensions:\")\n",
    "print(f\"   Rows (samples): {df.shape[0]}\")\n",
    "print(f\"   Columns (features): {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadae119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the data types and missing values\n",
    "print(\"\\nüìù Column Information:\")\n",
    "print(\"=\" * 70)\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüî¢ Data Types Summary:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n‚ùì Missing Values Summary:\")\n",
    "print(\"=\" * 70)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "display(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
    "\n",
    "print(f\"\\n‚úÖ Complete columns (no missing): {(missing == 0).sum()}/{len(missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for obvious outliers in numerical columns\n",
    "print(\"\\nüîç Quick Outlier Check:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numerical_cols:\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = ((df[col] < (q1 - 1.5 * iqr)) | (df[col] > (q3 + 1.5 * iqr))).sum()\n",
    "    if outliers > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  {col}: {outliers} potential outliers detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2935ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore correlations between numerical features\n",
    "print(\"\\nüîó Feature Correlations:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "numerical_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° High correlations (>0.7) might indicate redundant features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore our target variable (what we want to predict)\n",
    "print(\"\\nüéØ Target Variable Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "print(df['Diagnosis'].value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(df['Diagnosis'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['Diagnosis'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Distribution of Diagnosis', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Diagnosis')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of numerical features\n",
    "print(\"\\nüìà Statistical Summary of Numerical Features:\")\n",
    "print(\"=\" * 70)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c775d",
   "metadata": {},
   "source": [
    "### üí° Key Observations from Exploration:\n",
    "- Our dataset has mixed data types (numerical and categorical)\n",
    "- There are missing values that need handling\n",
    "- Some columns have inconsistent formats (units, text variations)\n",
    "- The target variable (Diagnosis) shows class distribution\n",
    "- We need to clean and prepare this data before modeling!\n",
    "\n",
    "---\n",
    "## üßπ STEP 2: Data Cleaning (20 minutes)\n",
    "\n",
    "Real-world data is messy! Let's clean it systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of our data\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"üîß Starting Data Cleaning Process...\\n\")\n",
    "\n",
    "# Reduce the dataframe to only necessary columns for modeling\n",
    "columns_to_drop = [\"Age_months\", \"Center\", \"Device_ID\", \"Collection_Date\", \"Notes\", \"ConstantFlag\"]\n",
    "df_clean = df_clean.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Clean Age column (handle \"years\" text and convert to numeric)\n",
    "print(\"1Ô∏è‚É£ Cleaning Age column...\")\n",
    "df_clean['Age [years]'] = df_clean['Age [years]'].astype(str).str.replace(' years', '').str.strip()\n",
    "df_clean['Age [years]'] = pd.to_numeric(df_clean['Age [years]'], errors='coerce')\n",
    "print(f\"   ‚úì Age column cleaned\")\n",
    "\n",
    "# 2. Clean Height column (standardize to cm)\n",
    "print(\"\\n2Ô∏è‚É£ Cleaning Height column...\")\n",
    "def clean_height(height):\n",
    "    if pd.isna(height):\n",
    "        return np.nan\n",
    "    height_str = str(height).strip()\n",
    "    if 'm' in height_str and 'cm' not in height_str:\n",
    "        # Convert meters to cm\n",
    "        return float(height_str.replace('m', '').strip()) * 100\n",
    "    elif 'cm' in height_str:\n",
    "        return float(height_str.replace('cm', '').strip())\n",
    "    else:\n",
    "        try:\n",
    "            return float(height_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "df_clean['Height'] = df_clean['Height'].apply(clean_height)\n",
    "print(f\"   ‚úì Height standardized to cm\")\n",
    "\n",
    "# 3. Clean Weight column (standardize to kg)\n",
    "print(\"\\n3Ô∏è‚É£ Cleaning Weight column...\")\n",
    "def clean_weight(weight):\n",
    "    if pd.isna(weight):\n",
    "        return np.nan\n",
    "    weight_str = str(weight).strip()\n",
    "    if 'lb' in weight_str:\n",
    "        # Convert pounds to kg\n",
    "        return float(weight_str.replace('lb', '').strip()) * 0.453592\n",
    "    elif 'kg' in weight_str:\n",
    "        return float(weight_str.replace('kg', '').strip())\n",
    "    else:\n",
    "        try:\n",
    "            return float(weight_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "df_clean['Weight'] = df_clean['Weight'].apply(clean_weight)\n",
    "print(f\"   ‚úì Weight standardized to kg\")\n",
    "\n",
    "print(\"\\n‚úÖ Basic cleaning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f14046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean Protein Concentration (remove commas, standardize units)\n",
    "print(\"4Ô∏è‚É£ Cleaning Protein Concentration...\")\n",
    "df_clean['Protein Concentration [mg/ml]'] = df_clean['Protein Concentration [mg/ml]'].astype(str).str.replace(',', '.').str.replace('mg/ml', '').str.strip()\n",
    "df_clean['Protein Concentration [mg/ml]'] = pd.to_numeric(df_clean['Protein Concentration [mg/ml]'], errors='coerce')\n",
    "print(f\"   ‚úì Protein concentration cleaned\")\n",
    "\n",
    "# 5. Clean pH column (remove \"pH\" text)\n",
    "print(\"\\n5Ô∏è‚É£ Cleaning pH column...\")\n",
    "df_clean['pH'] = df_clean['pH'].astype(str).str.replace('pH', '').str.replace('NA', '').str.strip()\n",
    "df_clean['pH'] = pd.to_numeric(df_clean['pH'], errors='coerce')\n",
    "print(f\"   ‚úì pH column cleaned\")\n",
    "\n",
    "# 6. Clean Albumin column (standardize format)\n",
    "print(\"\\n6Ô∏è‚É£ Cleaning Albumin column...\")\n",
    "df_clean['Albumin [g/L]'] = df_clean['Albumin [g/L]'].astype(str).str.replace('g/L', '').str.strip()\n",
    "df_clean['Albumin [g/L]'] = pd.to_numeric(df_clean['Albumin [g/L]'], errors='coerce')\n",
    "print(f\"   ‚úì Albumin column cleaned\")\n",
    "\n",
    "# 7. Standardize Sex column\n",
    "print(\"\\n7Ô∏è‚É£ Standardizing Sex column...\")\n",
    "df_clean['Sex'] = df_clean['Sex'].str.strip().str.upper()\n",
    "df_clean['Sex'] = df_clean['Sex'].replace({\n",
    "    'M': 'Male',\n",
    "    'F': 'Female',\n",
    "    'MALE': 'Male',\n",
    "    'FEMALE': 'Female'\n",
    "})\n",
    "print(f\"   ‚úì Sex column standardized\")\n",
    "print(f\"   Values: {df_clean['Sex'].value_counts().to_dict()}\")\n",
    "\n",
    "print(\"\\n‚úÖ All columns cleaned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the impact of cleaning\n",
    "print(\"\\nüìä Data Quality After Cleaning:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Original dataset: {df.shape}\")\n",
    "print(f\"Cleaned dataset: {df_clean.shape}\")\n",
    "\n",
    "print(\"\\n‚ùì Remaining Missing Values:\")\n",
    "missing_after = df_clean.isnull().sum()\n",
    "missing_pct_after = (missing_after / len(df_clean) * 100).round(2)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_after,\n",
    "    'Percentage': missing_pct_after\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing Count'] > 0].sort_values('Missing Count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values strategically\n",
    "print(\"üîß Handling Missing Values...\\n\")\n",
    "\n",
    "# Strategy 1: Fill numerical missing values with median (robust to outliers)\n",
    "numerical_cols = ['Age [years]', 'Height', 'Weight', 'BMI', \n",
    "                  'Protein Concentration [mg/ml]', 'pH', 'Glucose [mmol/L]', 'Albumin [g/L]']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            median_value = df_clean[col].median()\n",
    "            df_clean[col] = df_clean[col].fillna(median_value)\n",
    "            print(f\"   ‚úì Filled {missing_count} missing values in '{col}' with median: {median_value:.2f}\")\n",
    "\n",
    "# Strategy 2: Fill categorical missing values with mode (most common)\n",
    "categorical_cols = ['Sex', 'Treatment', 'Sample_Quality']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            mode_value = df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown'\n",
    "            df_clean[col] = df_clean[col].fillna(mode_value)\n",
    "            print(f\"   ‚úì Filled {missing_count} missing values in '{col}' with mode: {mode_value}\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing value handling completed!\")\n",
    "print(f\"\\nRemaining missing values: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e940a77",
   "metadata": {},
   "source": [
    "---\n",
    "## üî¨ STEP 3: Feature Engineering (15 minutes)\n",
    "\n",
    "Feature engineering means creating new useful features from existing ones. This can significantly improve model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Creating New Features...\\n\")\n",
    "\n",
    "# 1. Age groups (can reveal age-related patterns)\n",
    "print(\"1Ô∏è‚É£ Creating age groups...\")\n",
    "df_clean['Age_Group'] = pd.cut(df_clean['Age [years]'], \n",
    "                                bins=[0, 30, 45, 60, 100], \n",
    "                                labels=['Young', 'Middle', 'Senior', 'Elderly'])\n",
    "print(f\"   ‚úì Age groups created: {df_clean['Age_Group'].value_counts().to_dict()}\")\n",
    "\n",
    "# 2. BMI categories (WHO standard)\n",
    "print(\"\\n2Ô∏è‚É£ Creating BMI categories...\")\n",
    "df_clean['BMI_Category'] = pd.cut(df_clean['BMI'], \n",
    "                                   bins=[0, 18.5, 25, 30, 100], \n",
    "                                   labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "print(f\"   ‚úì BMI categories created\")\n",
    "\n",
    "# 3. Protein-to-Albumin ratio (medical significance)\n",
    "print(\"\\n3Ô∏è‚É£ Creating protein-to-albumin ratio...\")\n",
    "df_clean['Protein_Albumin_Ratio'] = df_clean['Protein Concentration [mg/ml]'] / df_clean['Albumin [g/L]']\n",
    "df_clean['Protein_Albumin_Ratio'] = df_clean['Protein_Albumin_Ratio'].replace([np.inf, -np.inf], np.nan)\n",
    "df_clean['Protein_Albumin_Ratio'] = df_clean['Protein_Albumin_Ratio'].fillna(df_clean['Protein_Albumin_Ratio'].median())\n",
    "print(f\"   ‚úì Protein-Albumin ratio created\")\n",
    "\n",
    "# 4. pH status (acidic vs alkaline)\n",
    "print(\"\\n4Ô∏è‚É£ Creating pH categories...\")\n",
    "df_clean['pH_Status'] = pd.cut(df_clean['pH'], \n",
    "                                bins=[0, 6.8, 7.2, 14], \n",
    "                                labels=['Acidic', 'Normal', 'Alkaline'])\n",
    "print(f\"   ‚úì pH status created\")\n",
    "\n",
    "# 5. Glucose level categories\n",
    "print(\"\\n5Ô∏è‚É£ Creating glucose categories...\")\n",
    "df_clean['Glucose_Level'] = pd.cut(df_clean['Glucose [mmol/L]'], \n",
    "                                    bins=[0, 5.5, 7, 20], \n",
    "                                    labels=['Normal', 'Prediabetic', 'Diabetic'])\n",
    "print(f\"   ‚úì Glucose levels categorized\")\n",
    "\n",
    "# 6. Is sample quality good?\n",
    "print(\"\\n6Ô∏è‚É£ Creating binary quality indicator...\")\n",
    "df_clean['Is_Good_Quality'] = df_clean['Sample_Quality'].apply(lambda x: 1 if x == 'Good' else 0)\n",
    "print(f\"   ‚úì Quality indicator created\")\n",
    "\n",
    "print(\"\\n‚úÖ Feature engineering completed!\")\n",
    "print(f\"New dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7deaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of our new features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Age Group vs Diagnosis\n",
    "age_diag = pd.crosstab(df_clean['Age_Group'], df_clean['Diagnosis'])\n",
    "age_diag.plot(kind='bar', ax=axes[0, 0], color=['green', 'red'])\n",
    "axes[0, 0].set_title('Diagnosis by Age Group', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Age Group')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].legend(title='Diagnosis')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: BMI Category vs Diagnosis\n",
    "bmi_diag = pd.crosstab(df_clean['BMI_Category'], df_clean['Diagnosis'])\n",
    "bmi_diag.plot(kind='bar', ax=axes[0, 1], color=['green', 'red'])\n",
    "axes[0, 1].set_title('Diagnosis by BMI Category', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('BMI Category')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].legend(title='Diagnosis')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Protein-Albumin Ratio distribution\n",
    "df_clean.boxplot(column='Protein_Albumin_Ratio', by='Diagnosis', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Protein-Albumin Ratio by Diagnosis', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Diagnosis')\n",
    "axes[1, 0].set_ylabel('Protein-Albumin Ratio')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Plot 4: Glucose Level vs Diagnosis\n",
    "glucose_diag = pd.crosstab(df_clean['Glucose_Level'], df_clean['Diagnosis'])\n",
    "glucose_diag.plot(kind='bar', ax=axes[1, 1], color=['green', 'red'])\n",
    "axes[1, 1].set_title('Diagnosis by Glucose Level', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Glucose Level')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].legend(title='Diagnosis')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° These visualizations help us understand which features might be useful for prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc64d3",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ STEP 4: Data Preparation for ML (10 minutes)\n",
    "\n",
    "Before training models, we need to prepare our data in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13922324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Preparing Data for Machine Learning...\\n\")\n",
    "\n",
    "# Step 1: Select features for modeling\n",
    "print(\"1Ô∏è‚É£ Selecting features...\")\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = [\n",
    "    'Age [years]', 'Height', 'Weight', 'BMI',\n",
    "    'Protein Concentration [mg/ml]', 'Hydrophobicity [score]',\n",
    "    'pH', 'Glucose [mmol/L]', 'Albumin [g/L]',\n",
    "    'Protein_Albumin_Ratio', 'Is_Good_Quality'\n",
    "]\n",
    "\n",
    "# Select categorical features that we'll encode\n",
    "categorical_features = ['Sex', 'Age_Group', 'BMI_Category', 'pH_Status', 'Glucose_Level']\n",
    "\n",
    "# Combine all features\n",
    "all_features = numerical_features + categorical_features\n",
    "\n",
    "print(f\"   ‚úì Selected {len(numerical_features)} numerical features\")\n",
    "print(f\"   ‚úì Selected {len(categorical_features)} categorical features\")\n",
    "print(f\"   Total features: {len(all_features)}\")\n",
    "\n",
    "# Step 2: Prepare target variable\n",
    "print(\"\\n2Ô∏è‚É£ Preparing target variable...\")\n",
    "# Convert target to binary (0 = Healthy, 1 = Tumor)\n",
    "df_clean['Target'] = df_clean['Diagnosis'].apply(lambda x: 1 if x == 'Tumor' else 0)\n",
    "print(f\"   ‚úì Target created: 0=Healthy, 1=Tumor\")\n",
    "print(f\"   Distribution: {df_clean['Target'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Encode categorical variables\n",
    "print(\"\\n3Ô∏è‚É£ Encoding categorical variables...\")\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "df_encoded = df_clean.copy()\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df_encoded.columns:\n",
    "        # Create dummy variables\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=True)\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "        print(f\"   ‚úì Encoded '{col}' into {len(dummies.columns)} features\")\n",
    "\n",
    "print(f\"\\n   Dataset shape after encoding: {df_encoded.shape}\")\n",
    "\n",
    "# Step 4: Create feature matrix (X) and target vector (y)\n",
    "print(\"\\n4Ô∏è‚É£ Creating feature matrix and target vector...\")\n",
    "\n",
    "# Get all feature columns (numerical + encoded categorical)\n",
    "feature_columns = numerical_features.copy()\n",
    "for col in categorical_features:\n",
    "    # Add the encoded dummy columns\n",
    "    feature_columns.extend([c for c in df_encoded.columns if c.startswith(col + '_')])\n",
    "\n",
    "# Remove original categorical columns from feature list\n",
    "feature_columns = [c for c in feature_columns if c in df_encoded.columns]\n",
    "\n",
    "X = df_encoded[feature_columns].copy()\n",
    "y = df_encoded['Target'].copy()\n",
    "\n",
    "print(f\"   ‚úì Feature matrix X: {X.shape}\")\n",
    "print(f\"   ‚úì Target vector y: {y.shape}\")\n",
    "print(f\"   ‚úì Total features for modeling: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split data into training and testing sets\n",
    "print(\"\\n5Ô∏è‚É£ Splitting data into train and test sets...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing, 80% for training\n",
    "    random_state=42,     # For reproducibility\n",
    "    stratify=y          # Maintain class proportions\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úì Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\n   Training set class distribution:\")\n",
    "print(f\"      Healthy: {(y_train == 0).sum()} | Tumor: {(y_train == 1).sum()}\")\n",
    "print(f\"   Test set class distribution:\")\n",
    "print(f\"      Healthy: {(y_test == 0).sum()} | Tumor: {(y_test == 1).sum()}\")\n",
    "\n",
    "# Step 6: Scale features (important for many ML algorithms)\n",
    "print(\"\\n6Ô∏è‚É£ Scaling features...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"   ‚úì Features scaled using StandardScaler\")\n",
    "print(f\"   ‚úì Mean ‚âà 0, Standard Deviation ‚âà 1\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation completed! Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a3425",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ STEP 5: Model Training (25 minutes)\n",
    "\n",
    "Now the exciting part! We'll train multiple ML models and see which performs best.\n",
    "\n",
    "### Why Multiple Models?\n",
    "Different algorithms have different strengths. By trying several, we find the best fit for our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "print(\"‚úÖ All required models and metrics imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our models to train\n",
    "print(\"ü§ñ Initializing Machine Learning Models...\\n\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(f\"üìã Models to train: {len(models)}\")\n",
    "for i, name in enumerate(models.keys(), 1):\n",
    "    print(f\"   {i}. {name}\")\n",
    "\n",
    "print(\"\\nüí° Brief explanation of each model:\")\n",
    "print(\"   ‚Ä¢ Logistic Regression: Linear model, fast and interpretable\")\n",
    "print(\"   ‚Ä¢ Decision Tree: Rule-based model, easy to visualize\")\n",
    "print(\"   ‚Ä¢ Random Forest: Ensemble of decision trees, robust\")\n",
    "print(\"   ‚Ä¢ Gradient Boosting: Sequential tree learning, powerful\")\n",
    "print(\"   ‚Ä¢ SVM: Finds optimal decision boundary\")\n",
    "print(\"   ‚Ä¢ K-Nearest Neighbors: Classification by similarity\")\n",
    "print(\"   ‚Ä¢ Naive Bayes: Probabilistic model based on Bayes theorem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc61504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models and collect results\n",
    "print(\"\\nüèãÔ∏è Training Models...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "import time\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    \n",
    "    # Record training time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Training Time': training_time\n",
    "    }\n",
    "    \n",
    "    # Store trained model\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    print(f\"   ‚úì Completed in {training_time:.3f} seconds\")\n",
    "    print(f\"   Accuracy: {accuracy:.3f} | Precision: {precision:.3f} | Recall: {recall:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba92f3d",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä STEP 6: Model Evaluation (10 minutes)\n",
    "\n",
    "Let's compare all our models and understand their performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive results table\n",
    "print(\"üìä Model Performance Comparison\\n\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\nüí° Understanding the Metrics:\")\n",
    "print(\"   ‚Ä¢ Accuracy: Overall correctness (how many predictions were right)\")\n",
    "print(\"   ‚Ä¢ Precision: Of predicted positives, how many were actually positive\")\n",
    "print(\"   ‚Ä¢ Recall: Of actual positives, how many did we catch\")\n",
    "print(\"   ‚Ä¢ F1-Score: Balance between Precision and Recall (harmonic mean)\")\n",
    "print(\"   ‚Ä¢ Training Time: How long it took to train the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "results_df['Accuracy'].plot(kind='barh', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_xlabel('Accuracy Score')\n",
    "axes[0, 0].set_title('Model Accuracy Comparison', fontweight='bold', fontsize=12)\n",
    "axes[0, 0].set_xlim([0, 1])\n",
    "axes[0, 0].axvline(x=results_df['Accuracy'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: Precision vs Recall\n",
    "axes[0, 1].scatter(results_df['Recall'], results_df['Precision'], s=200, alpha=0.6, c='coral')\n",
    "for idx, name in enumerate(results_df.index):\n",
    "    axes[0, 1].annotate(name, \n",
    "                        (results_df['Recall'].iloc[idx], results_df['Precision'].iloc[idx]),\n",
    "                        fontsize=8, ha='center')\n",
    "axes[0, 1].set_xlabel('Recall')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('Precision vs Recall Trade-off', fontweight='bold', fontsize=12)\n",
    "axes[0, 1].set_xlim([0, 1])\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: F1-Score Comparison\n",
    "results_df['F1-Score'].plot(kind='barh', ax=axes[1, 0], color='lightgreen')\n",
    "axes[1, 0].set_xlabel('F1-Score')\n",
    "axes[1, 0].set_title('Model F1-Score Comparison', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_xlim([0, 1])\n",
    "axes[1, 0].axvline(x=results_df['F1-Score'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Plot 4: Training Time\n",
    "results_df['Training Time'].plot(kind='barh', ax=axes[1, 1], color='plum')\n",
    "axes[1, 1].set_xlabel('Training Time (seconds)')\n",
    "axes[1, 1].set_title('Model Training Time', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° These visualizations help us see performance trade-offs at a glance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568673be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the best model\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ Best Performing Model: {best_model_name}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Make predictions with best model\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot confusion matrix\n",
    "im = axes[0].imshow(cm, cmap='Blues')\n",
    "axes[0].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels(['Healthy', 'Tumor'])\n",
    "axes[0].set_yticklabels(['Healthy', 'Tumor'])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = axes[0].text(j, i, cm[i, j], ha=\"center\", va=\"center\", \n",
    "                           color=\"white\" if cm[i, j] > cm.max()/2 else \"black\",\n",
    "                           fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred_best, target_names=['Healthy', 'Tumor'], output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "axes[1].axis('off')\n",
    "table = axes[1].table(cellText=report_df.round(2).values,\n",
    "                     colLabels=report_df.columns,\n",
    "                     rowLabels=report_df.index,\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     bbox=[0, 0, 1, 1])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "axes[1].set_title(f'Classification Report - {best_model_name}', \n",
    "                 fontweight='bold', fontsize=12, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Confusion Matrix shows:\")\n",
    "print(f\"   ‚Ä¢ True Negatives (Healthy‚ÜíHealthy): {cm[0,0]}\")\n",
    "print(f\"   ‚Ä¢ False Positives (Healthy‚ÜíTumor): {cm[0,1]}\")\n",
    "print(f\"   ‚Ä¢ False Negatives (Tumor‚ÜíHealthy): {cm[1,0]}\")\n",
    "print(f\"   ‚Ä¢ True Positives (Tumor‚ÜíTumor): {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0598ad3",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÜ STEP 7: Model Selection & Final Thoughts (5 minutes)\n",
    "\n",
    "Time to make our final decision and understand what we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e454a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Selection\n",
    "print(\"üéØ MODEL SELECTION CRITERIA\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWhen choosing the best model, consider:\\n\")\n",
    "print(\"1Ô∏è‚É£ ACCURACY: Overall performance - highest is often best\")\n",
    "print(\"2Ô∏è‚É£ F1-SCORE: Balance of precision and recall - important for imbalanced data\")\n",
    "print(\"3Ô∏è‚É£ RECALL: Critical in medical diagnosis - we don't want to miss tumors!\")\n",
    "print(\"4Ô∏è‚É£ PRECISION: Avoid false alarms - but less critical than recall here\")\n",
    "print(\"5Ô∏è‚É£ TRAINING TIME: Efficiency matters for deployment\")\n",
    "print(\"6Ô∏è‚É£ INTERPRETABILITY: Can stakeholders understand the model?\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèÜ FINAL MODEL RECOMMENDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get top 3 models by accuracy\n",
    "top_3 = results_df.head(3)\n",
    "\n",
    "print(\"\\nüìä Top 3 Models by Accuracy:\")\n",
    "for idx, (model_name, metrics) in enumerate(top_3.iterrows(), 1):\n",
    "    print(f\"\\n{idx}. {model_name}\")\n",
    "    print(f\"   Accuracy:  {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['F1-Score']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['Recall']:.4f}\")\n",
    "    print(f\"   Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"   Time:      {metrics['Training Time']:.4f}s\")\n",
    "\n",
    "# Select best model based on F1-score (balanced metric)\n",
    "best_by_f1 = results_df.sort_values('F1-Score', ascending=False).index[0]\n",
    "best_by_recall = results_df.sort_values('Recall', ascending=False).index[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ RECOMMENDED MODEL:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úÖ Best Overall (F1-Score): {best_by_f1}\")\n",
    "print(f\"   ‚Üí Balanced performance across all metrics\")\n",
    "print(f\"\\n‚öïÔ∏è  Best for Medical Use (Recall): {best_by_recall}\")\n",
    "print(f\"   ‚Üí Minimizes missed tumor cases (false negatives)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° KEY TAKEAWAYS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "For our biotech diagnostic task, we recommend: {}\n",
    "\n",
    "REASONING:\n",
    "‚Ä¢ Medical diagnosis requires HIGH RECALL (catching all tumors is critical)\n",
    "‚Ä¢ F1-Score ensures we balance precision and recall\n",
    "‚Ä¢ The model shows consistent performance across metrics\n",
    "‚Ä¢ Training time is reasonable for practical deployment\n",
    "\n",
    "NEXT STEPS:\n",
    "‚Ä¢ Validate on additional test data\n",
    "‚Ä¢ Fine-tune hyperparameters for even better performance\n",
    "‚Ä¢ Deploy in a production environment\n",
    "‚Ä¢ Monitor performance over time\n",
    "\"\"\".format(best_by_f1 if results_df.loc[best_by_f1, 'Recall'] >= results_df['Recall'].quantile(0.75) else best_by_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8f43a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model and preprocessing components\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "final_model_name = best_by_f1 if results_df.loc[best_by_f1, 'Recall'] >= results_df['Recall'].quantile(0.75) else best_by_recall\n",
    "final_model = trained_models[final_model_name]\n",
    "\n",
    "# Save model\n",
    "model_filename = 'models/best_model.joblib'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "# Save scaler (important for preprocessing new data!)\n",
    "scaler_filename = 'models/scaler.joblib'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "\n",
    "# Save feature names (important to know what features the model expects!)\n",
    "feature_names_filename = 'models/feature_names.joblib'\n",
    "joblib.dump(X_train.columns.tolist(), feature_names_filename)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': final_model_name,\n",
    "    'model_type': type(final_model).__name__,\n",
    "    'n_features': X_train.shape[1],\n",
    "    'feature_names': X_train.columns.tolist(),\n",
    "    'performance': results_df.loc[final_model_name].to_dict(),\n",
    "    'training_date': '2025-12-01'\n",
    "}\n",
    "metadata_filename = 'models/model_metadata.joblib'\n",
    "joblib.dump(metadata, metadata_filename)\n",
    "\n",
    "print(f\"‚úÖ Model saved as '{model_filename}'\")\n",
    "print(f\"‚úÖ Scaler saved as '{scaler_filename}'\")\n",
    "print(f\"‚úÖ Feature names saved as '{feature_names_filename}'\")\n",
    "print(f\"‚úÖ Metadata saved as '{metadata_filename}'\")\n",
    "print(f\"\\nüì¶ Model Details:\")\n",
    "print(f\"   Name: {final_model_name}\")\n",
    "print(f\"   Type: {type(final_model).__name__}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nüíæ To load this model later, use:\")\n",
    "print(f\"   loaded_model = joblib.load('{model_filename}')\")\n",
    "print(f\"   scaler = joblib.load('{scaler_filename}')\")\n",
    "print(f\"   feature_names = joblib.load('{feature_names_filename}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5830e",
   "metadata": {},
   "source": [
    "---\n",
    "# Appendix: BONUS\n",
    "\n",
    "This appendix contains optional bonus cells: feature importance analysis and a short example showing how to make a single prediction with the saved artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12031074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Feature Importance Analysis (if time permits)\n",
    "if 'final_model' in globals() and hasattr(final_model, 'feature_importances_'):\n",
    "    print(\"üîç BONUS: Feature Importance Analysis\\n\")\n",
    "    importances = final_model.feature_importances_\n",
    "    feature_names = X_train.columns if 'X_train' in globals() else []\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "    display(importance_df.head(15))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    importance_df.head(15).plot(kind='barh', x='Feature', y='Importance', legend=False, color='steelblue')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Feature importances not available for the current model.\")\n",
    "    try: \n",
    "        decision_tree_model = trained_models[\"Decision Tree\"]\n",
    "        importances = decision_tree_model.feature_importances_\n",
    "        feature_names = X_train.columns if 'X_train' in globals() else []\n",
    "        importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "\n",
    "        print(\"üîç Feature Importance Analysis for the Decision Tree model used instead\\n\")\n",
    "        display(importance_df.head(15))\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        importance_df.head(15).plot(kind='barh', x='Feature', y='Importance', legend=False, color='steelblue')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Quick prediction example using saved artifacts\n",
    "if os.path.exists('models/best_model.joblib'):\n",
    "    print('üîÆ BONUS: Making a single prediction with the saved model')\n",
    "    loaded_model = joblib.load('models/best_model.joblib')\n",
    "    loaded_scaler = joblib.load('models/scaler.joblib')\n",
    "    feature_names = joblib.load('models/feature_names.joblib')\n",
    "    # Create a template using the first row of X_train if available\n",
    "    if 'X_train' in globals():\n",
    "        new_sample = X_train.iloc[0:1].copy()\n",
    "        new_sample_scaled = loaded_scaler.transform(new_sample)\n",
    "        pred = loaded_model.predict(new_sample_scaled)\n",
    "        proba = loaded_model.predict_proba(new_sample_scaled) if hasattr(loaded_model, 'predict_proba') else None\n",
    "        print(f\"Predicted class: {pred[0]}\")\n",
    "        if proba is not None:\n",
    "            print(f\"Probabilities: {proba[0]}\")\n",
    "    else:\n",
    "        print('No X_train available to build a quick sample. Use the prediction demo notebook instead.')\n",
    "else:\n",
    "    print('Saved model artifacts not found in models/. Run the training cells first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175a776",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Workshop Summary & Key Learnings\n",
    "\n",
    "### üåü Congratulations! You've completed a full ML workflow!\n",
    "\n",
    "---\n",
    "\n",
    "### üìö What You Learned:\n",
    "\n",
    "#### 1. **Data Exploration** (15 min)\n",
    "- How to load and inspect datasets\n",
    "- Identifying data types and missing values\n",
    "- Understanding target variable distribution\n",
    "- Basic statistical analysis\n",
    "\n",
    "#### 2. **Data Cleaning** (20 min)\n",
    "- Standardizing units and formats\n",
    "- Handling inconsistent text data\n",
    "- Converting data types\n",
    "- Dealing with missing values using median/mode strategies\n",
    "\n",
    "#### 3. **Feature Engineering** (15 min)\n",
    "- Creating categorical features (age groups, BMI categories)\n",
    "- Computing derived features (ratios, indicators)\n",
    "- Using domain knowledge to enhance data\n",
    "- Visualizing feature relationships\n",
    "\n",
    "#### 4. **Data Preparation** (10 min)\n",
    "- Selecting relevant features\n",
    "- Encoding categorical variables\n",
    "- Splitting data into train/test sets\n",
    "- Feature scaling for algorithm optimization\n",
    "\n",
    "#### 5. **Model Training** (25 min)\n",
    "- Training 7 different ML algorithms\n",
    "- Understanding algorithm differences\n",
    "- Measuring training time\n",
    "- Making predictions\n",
    "\n",
    "#### 6. **Model Evaluation** (10 min)\n",
    "- Computing multiple metrics (accuracy, precision, recall, F1)\n",
    "- Creating performance visualizations\n",
    "- Analyzing confusion matrices\n",
    "- Understanding metric trade-offs\n",
    "\n",
    "#### 7. **Model Selection** (5 min)\n",
    "- Comparing models systematically\n",
    "- Choosing based on problem requirements\n",
    "- Documenting decisions\n",
    "- Saving final model\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Key Takeaways:\n",
    "\n",
    "‚úÖ **ML is iterative**: Real projects involve multiple cycles of improvement\n",
    "\n",
    "‚úÖ **Data quality matters**: Clean, well-prepared data is crucial for success\n",
    "\n",
    "‚úÖ **No single best model**: Different algorithms work better for different problems\n",
    "\n",
    "‚úÖ **Context is king**: Medical diagnosis prioritizes recall (catching all positives)\n",
    "\n",
    "‚úÖ **Evaluate comprehensively**: Use multiple metrics, not just accuracy\n",
    "\n",
    "‚úÖ **Document everything**: Clear documentation helps reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next Steps to Continue Learning:\n",
    "\n",
    "1. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV\n",
    "2. **Cross-Validation**: Use k-fold CV for more robust evaluation\n",
    "3. **Feature Selection**: Identify the most important features\n",
    "4. **Handle Class Imbalance**: Try SMOTE, class weights, or threshold tuning\n",
    "5. **Ensemble Methods**: Combine multiple models (stacking, voting)\n",
    "6. **Deep Learning**: Explore neural networks for more complex patterns\n",
    "7. **Model Deployment**: Learn Flask, FastAPI, or cloud platforms\n",
    "8. **MLOps**: Study model monitoring and continuous improvement\n",
    "\n",
    "---\n",
    "\n",
    "### üìñ Recommended Resources:\n",
    "\n",
    "- **Scikit-learn Documentation**: https://scikit-learn.org/\n",
    "- **Kaggle**: Practice on real datasets\n",
    "- **Google's ML Crash Course**: Free online course\n",
    "- **Papers with Code**: Latest ML research\n",
    "- **Towards Data Science**: Practical ML tutorials\n",
    "\n",
    "---\n",
    "\n",
    "### üí™ Practice Exercise Ideas:\n",
    "\n",
    "1. Try different feature engineering approaches\n",
    "2. Experiment with hyperparameter tuning\n",
    "3. Build a simple web app to use your model\n",
    "4. Work with a different dataset\n",
    "5. Implement custom evaluation metrics\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Thank you for participating!\n",
    "\n",
    "You now have a solid foundation in machine learning workflows. Keep practicing and building projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f903249",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
