{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3901167c",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\")\n",
    "base_dir = Path().resolve().parent.parent\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961d6a0",
   "metadata": {},
   "source": [
    "## ðŸ”“ Step 2: Load the Trained Model and Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dcd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‚ Loading model and preprocessing components...\\n\")\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('models/best_model.joblib')\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "# Load the scaler (used to standardize features)\n",
    "scaler = joblib.load('models/scaler.joblib')\n",
    "print(\"âœ… Scaler loaded\")\n",
    "\n",
    "# Load feature names (to ensure correct order)\n",
    "feature_names = joblib.load('models/feature_names.joblib')\n",
    "print(\"âœ… Feature names loaded\")\n",
    "\n",
    "# Load metadata (model information)\n",
    "metadata = joblib.load('models/model_metadata.joblib')\n",
    "print(\"âœ… Metadata loaded\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š MODEL INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model Name: {metadata['model_name']}\")\n",
    "print(f\"Model Type: {metadata['model_type']}\")\n",
    "print(f\"Number of Features: {metadata['n_features']}\")\n",
    "print(f\"Training Date: {metadata['training_date']}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "for metric, value in metadata['performance'].items():\n",
    "    if metric != 'Training Time':\n",
    "        print(f\"  â€¢ {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  â€¢ {metric}: {value:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3717365",
   "metadata": {},
   "source": [
    "## ðŸŽ² Step 3: Generate Synthetic Patient Data\n",
    "\n",
    "Let's create realistic test data for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ² Generating synthetic patient data...\\n\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of synthetic patients to generate\n",
    "n_patients = 20\n",
    "\n",
    "# Generate realistic patient data\n",
    "synthetic_data = {\n",
    "    'Patient_ID': [f'P{i+1:03d}' for i in range(n_patients)],\n",
    "    'Age [years]': np.random.uniform(25, 80, n_patients).round(1),\n",
    "    'Height': np.random.uniform(150, 190, n_patients).round(1),\n",
    "    'Weight': np.random.uniform(50, 100, n_patients).round(1),\n",
    "    'BMI': None,  # Will calculate\n",
    "    'Protein Concentration [mg/ml]': np.random.uniform(2.5, 7.5, n_patients).round(2),\n",
    "    'Hydrophobicity [score]': np.random.uniform(10, 100, n_patients).round(1),\n",
    "    'pH': np.random.uniform(6.5, 7.8, n_patients).round(2),\n",
    "    'Glucose [mmol/L]': np.random.uniform(3.0, 8.5, n_patients).round(2),\n",
    "    'Albumin [g/L]': np.random.uniform(30, 50, n_patients).round(1),\n",
    "    'Sex': np.random.choice(['Male', 'Female'], n_patients),\n",
    "    'Sample_Quality': np.random.choice(['Good', 'OK', 'Poor'], n_patients, p=[0.6, 0.3, 0.1])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_new = pd.DataFrame(synthetic_data)\n",
    "\n",
    "# Calculate BMI\n",
    "df_new['BMI'] = (df_new['Weight'] / (df_new['Height'] / 100) ** 2).round(1)\n",
    "\n",
    "# Create engineered features (same as training)\n",
    "df_new['Age_Group'] = pd.cut(df_new['Age [years]'], \n",
    "                              bins=[0, 30, 45, 60, 100], \n",
    "                              labels=['Young', 'Middle', 'Senior', 'Elderly'])\n",
    "\n",
    "df_new['BMI_Category'] = pd.cut(df_new['BMI'], \n",
    "                                 bins=[0, 18.5, 25, 30, 100], \n",
    "                                 labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "\n",
    "df_new['Protein_Albumin_Ratio'] = df_new['Protein Concentration [mg/ml]'] / df_new['Albumin [g/L]']\n",
    "\n",
    "df_new['pH_Status'] = pd.cut(df_new['pH'], \n",
    "                              bins=[0, 6.8, 7.2, 14], \n",
    "                              labels=['Acidic', 'Normal', 'Alkaline'])\n",
    "\n",
    "df_new['Glucose_Level'] = pd.cut(df_new['Glucose [mmol/L]'], \n",
    "                                  bins=[0, 5.5, 7, 20], \n",
    "                                  labels=['Normal', 'Prediabetic', 'Diabetic'])\n",
    "\n",
    "df_new['Is_Good_Quality'] = df_new['Sample_Quality'].apply(lambda x: 1 if x == 'Good' else 0)\n",
    "\n",
    "print(f\"âœ… Generated {n_patients} synthetic patients\")\n",
    "print(f\"\\nðŸ“Š Sample Data (first 5 patients):\")\n",
    "display(df_new[['Patient_ID', 'Age [years]', 'Sex', 'BMI', 'Glucose [mmol/L]', 'pH']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb849f",
   "metadata": {},
   "source": [
    "## ðŸ”„ Step 4: Prepare Data for Prediction\n",
    "\n",
    "We need to encode categorical variables and ensure features match the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Preparing data for prediction...\\n\")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = ['Sex', 'Age_Group', 'BMI_Category', 'pH_Status', 'Glucose_Level']\n",
    "df_encoded = df_new.copy()\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in df_encoded.columns:\n",
    "        dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=True)\n",
    "        df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "\n",
    "# Ensure we have all the features the model expects\n",
    "# Create a DataFrame with all required features\n",
    "X_new = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "# Fill in the values we have\n",
    "for col in feature_names:\n",
    "    if col in df_encoded.columns:\n",
    "        X_new[col] = df_encoded[col].values\n",
    "    else:\n",
    "        # If a feature is missing (e.g., a categorical level), fill with 0\n",
    "        X_new[col] = 0\n",
    "\n",
    "# Convert to numeric\n",
    "X_new = X_new.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"âœ… Data prepared with {X_new.shape[1]} features\")\n",
    "print(f\"âœ… Data shape: {X_new.shape}\")\n",
    "print(f\"\\nðŸ“‹ Feature names match: {list(X_new.columns) == feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b24dc",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 5: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea21a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ¯ Making predictions...\\n\")\n",
    "\n",
    "# Scale the features (using the same scaler from training)\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "print(\"âœ… Features scaled\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new_scaled)\n",
    "print(\"âœ… Predictions generated\")\n",
    "\n",
    "# Get prediction probabilities (if available)\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    probabilities = model.predict_proba(X_new_scaled)\n",
    "    print(\"âœ… Prediction probabilities calculated\")\n",
    "else:\n",
    "    probabilities = None\n",
    "    print(\"âš ï¸  Model doesn't support probability predictions\")\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "df_new['Prediction'] = predictions\n",
    "df_new['Diagnosis_Predicted'] = df_new['Prediction'].apply(lambda x: 'Tumor' if x == 1 else 'Healthy')\n",
    "\n",
    "if probabilities is not None:\n",
    "    df_new['Probability_Healthy'] = probabilities[:, 0]\n",
    "    df_new['Probability_Tumor'] = probabilities[:, 1]\n",
    "    df_new['Confidence'] = df_new[['Probability_Healthy', 'Probability_Tumor']].max(axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š PREDICTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total patients: {len(df_new)}\")\n",
    "print(f\"Predicted Healthy: {(df_new['Prediction'] == 0).sum()}\")\n",
    "print(f\"Predicted Tumor: {(df_new['Prediction'] == 1).sum()}\")\n",
    "\n",
    "if probabilities is not None:\n",
    "    print(f\"\\nAverage confidence: {df_new['Confidence'].mean():.2%}\")\n",
    "    print(f\"Min confidence: {df_new['Confidence'].min():.2%}\")\n",
    "    print(f\"Max confidence: {df_new['Confidence'].max():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bfcca",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 6: Display Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‹ DETAILED PREDICTION RESULTS\\n\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Select columns to display\n",
    "if probabilities is not None:\n",
    "    display_cols = ['Patient_ID', 'Age [years]', 'Sex', 'BMI', 'Glucose [mmol/L]', \n",
    "                    'Diagnosis_Predicted', 'Probability_Healthy', 'Probability_Tumor', 'Confidence']\n",
    "else:\n",
    "    display_cols = ['Patient_ID', 'Age [years]', 'Sex', 'BMI', 'Glucose [mmol/L]', 'Diagnosis_Predicted']\n",
    "\n",
    "results_display = df_new[display_cols].copy()\n",
    "\n",
    "# Format probabilities as percentages\n",
    "if probabilities is not None:\n",
    "    results_display['Probability_Healthy'] = results_display['Probability_Healthy'].apply(lambda x: f\"{x:.1%}\")\n",
    "    results_display['Probability_Tumor'] = results_display['Probability_Tumor'].apply(lambda x: f\"{x:.1%}\")\n",
    "    results_display['Confidence'] = results_display['Confidence'].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "display(results_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00c025",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 7: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“ˆ Creating visualizations...\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Prediction Distribution\n",
    "diagnosis_counts = df_new['Diagnosis_Predicted'].value_counts()\n",
    "colors = ['green', 'red']\n",
    "axes[0, 0].bar(diagnosis_counts.index, diagnosis_counts.values, color=colors)\n",
    "axes[0, 0].set_title('Prediction Distribution', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_xlabel('Diagnosis')\n",
    "for i, v in enumerate(diagnosis_counts.values):\n",
    "    axes[0, 0].text(i, v + 0.3, str(v), ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Plot 2: Confidence Distribution\n",
    "if probabilities is not None:\n",
    "    axes[0, 1].hist(df_new['Confidence'], bins=15, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Prediction Confidence Distribution', fontweight='bold', fontsize=14)\n",
    "    axes[0, 1].set_xlabel('Confidence Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].axvline(df_new['Confidence'].mean(), color='red', linestyle='--', \n",
    "                       linewidth=2, label=f'Mean: {df_new[\"Confidence\"].mean():.2%}')\n",
    "    axes[0, 1].legend()\n",
    "else:\n",
    "    axes[0, 1].text(0.5, 0.5, 'Confidence scores\\nnot available', \n",
    "                    ha='center', va='center', fontsize=14, transform=axes[0, 1].transAxes)\n",
    "    axes[0, 1].set_title('Prediction Confidence Distribution', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Plot 3: Age vs Diagnosis\n",
    "for diagnosis in df_new['Diagnosis_Predicted'].unique():\n",
    "    subset = df_new[df_new['Diagnosis_Predicted'] == diagnosis]\n",
    "    color = 'green' if diagnosis == 'Healthy' else 'red'\n",
    "    axes[1, 0].scatter(subset['Age [years]'], subset['BMI'], \n",
    "                       label=diagnosis, alpha=0.6, s=100, color=color, edgecolors='black')\n",
    "axes[1, 0].set_title('Age vs BMI by Predicted Diagnosis', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].set_xlabel('Age (years)')\n",
    "axes[1, 0].set_ylabel('BMI')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Glucose vs Protein by Diagnosis\n",
    "for diagnosis in df_new['Diagnosis_Predicted'].unique():\n",
    "    subset = df_new[df_new['Diagnosis_Predicted'] == diagnosis]\n",
    "    color = 'green' if diagnosis == 'Healthy' else 'red'\n",
    "    axes[1, 1].scatter(subset['Glucose [mmol/L]'], subset['Protein Concentration [mg/ml]'], \n",
    "                       label=diagnosis, alpha=0.6, s=100, color=color, edgecolors='black')\n",
    "axes[1, 1].set_title('Glucose vs Protein by Predicted Diagnosis', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Glucose (mmol/L)')\n",
    "axes[1, 1].set_ylabel('Protein Concentration (mg/ml)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualizations created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9b23",
   "metadata": {},
   "source": [
    "## ðŸ” Step 8: Highlight High-Risk Patients\n",
    "\n",
    "Identify patients with tumor predictions and high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš ï¸  HIGH-RISK PATIENTS (Tumor Predictions)\\n\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "high_risk = df_new[df_new['Diagnosis_Predicted'] == 'Tumor'].copy()\n",
    "\n",
    "if len(high_risk) > 0:\n",
    "    if probabilities is not None:\n",
    "        high_risk = high_risk.sort_values('Probability_Tumor', ascending=False)\n",
    "        display_cols = ['Patient_ID', 'Age [years]', 'Sex', 'BMI', 'Glucose [mmol/L]', \n",
    "                        'Protein Concentration [mg/ml]', 'pH', 'Probability_Tumor']\n",
    "    else:\n",
    "        display_cols = ['Patient_ID', 'Age [years]', 'Sex', 'BMI', 'Glucose [mmol/L]', \n",
    "                        'Protein Concentration [mg/ml]', 'pH']\n",
    "    \n",
    "    print(f\"Found {len(high_risk)} patients with tumor predictions:\\n\")\n",
    "    display(high_risk[display_cols])\n",
    "    \n",
    "    print(\"\\nðŸ’¡ These patients should be prioritized for further medical evaluation.\")\n",
    "else:\n",
    "    print(\"âœ… No high-risk patients identified in this batch.\")\n",
    "    print(\"   All patients predicted as Healthy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ce819",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 9: Save Predictions to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbea571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ’¾ Saving predictions to file...\\n\")\n",
    "\n",
    "# Create output filename with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_filename = f'predictions_{timestamp}.csv'\n",
    "\n",
    "# Select columns to save\n",
    "if probabilities is not None:\n",
    "    save_cols = ['Patient_ID', 'Age [years]', 'Sex', 'Height', 'Weight', 'BMI',\n",
    "                 'Protein Concentration [mg/ml]', 'Glucose [mmol/L]', 'pH', 'Albumin [g/L]',\n",
    "                 'Diagnosis_Predicted', 'Probability_Healthy', 'Probability_Tumor', 'Confidence']\n",
    "else:\n",
    "    save_cols = ['Patient_ID', 'Age [years]', 'Sex', 'Height', 'Weight', 'BMI',\n",
    "                 'Protein Concentration [mg/ml]', 'Glucose [mmol/L]', 'pH', 'Albumin [g/L]',\n",
    "                 'Diagnosis_Predicted']\n",
    "\n",
    "df_new[save_cols].to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Predictions saved to '{output_filename}'\")\n",
    "print(f\"ðŸ“Š Saved {len(df_new)} patient predictions\")\n",
    "print(f\"\\nðŸ’¡ You can open this file in Excel or any CSV viewer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cbac0",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "âœ… **Loaded** the trained model and preprocessing components  \n",
    "âœ… **Generated** realistic synthetic patient data  \n",
    "âœ… **Prepared** data with proper feature engineering  \n",
    "âœ… **Made** predictions with confidence scores  \n",
    "âœ… **Visualized** prediction results  \n",
    "âœ… **Identified** high-risk patients  \n",
    "âœ… **Saved** predictions to a CSV file  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "\n",
    "1. **Use Real Data**: Replace synthetic data with actual patient records\n",
    "2. **Batch Processing**: Process multiple files automatically\n",
    "3. **API Integration**: Create a web service for real-time predictions\n",
    "4. **Model Monitoring**: Track prediction distributions over time\n",
    "5. **Validation**: Compare predictions with actual diagnoses when available\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ Key Points:\n",
    "\n",
    "- Always use the **same preprocessing** (scaling, encoding) as training\n",
    "- Keep feature names and order **consistent**\n",
    "- Save both **model and preprocessing components**\n",
    "- Document model **metadata** for reproducibility\n",
    "- Prioritize high-risk predictions for **medical review**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
